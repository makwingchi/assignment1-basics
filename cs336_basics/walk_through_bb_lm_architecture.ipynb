{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da7cd335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4da30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62578a76",
   "metadata": {},
   "source": [
    "# Transformer Language Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43a1fc",
   "metadata": {},
   "source": [
    "## Basic Building Blocks: Linear and Embedding Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494286c2",
   "metadata": {},
   "source": [
    "### Linear Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac573f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        mean = 0\n",
    "        std = (2 / (in_features + out_features)) ** 0.5\n",
    "\n",
    "        self.W = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(\n",
    "                    out_features, \n",
    "                    in_features,\n",
    "                    device=\"cpu\" if device is None else device,\n",
    "                    dtype=torch.float32 if dtype is None else dtype\n",
    "                ), \n",
    "                a=-3*std, \n",
    "                b=3*std\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x @ self.W.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fdaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694a9cfd",
   "metadata": {},
   "source": [
    "### Embedding Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(\n",
    "                    num_embeddings, \n",
    "                    embedding_dim,\n",
    "                    device=\"cpu\" if device is None else device,\n",
    "                    dtype=torch.float32 if dtype is None else dtype\n",
    "                ),\n",
    "                a=-3, b=3\n",
    "            )\n",
    "        )\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        one_hot = F.one_hot(token_ids, num_classes=self.num_embeddings).to(self.embedding.dtype) # batch_size, sequence_length, num_embeddings\n",
    "        return one_hot @ self.embedding # batch_size, sequence_length, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be77762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66518362",
   "metadata": {},
   "source": [
    "## Pre-Norm Transformer Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6ffd",
   "metadata": {},
   "source": [
    "### Root Mean Square Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRMSNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps: float = 1e-5, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.gain = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(d_model, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "\n",
    "        x_sum = torch.sum(x**2, dim=-1, keepdim=True)\n",
    "        rms = torch.sqrt(\n",
    "            x_sum / self.d_model + self.eps\n",
    "        )\n",
    "\n",
    "        result = self.gain * x / rms\n",
    "        return result.to(in_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28363fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8baac196",
   "metadata": {},
   "source": [
    "### Position-Wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50ee4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "346e2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGLU(nn.Module):\n",
    "    def __init__(self, d_model, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.W1 = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(8 * d_model // 3, d_model, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.W2 = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(8 * d_model // 3, d_model, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(x @ self.W1.T) * (x @ self.W2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7731b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySwiGLU(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(d_ff, d_model, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.W2 = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(d_model, d_ff, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.W3 = nn.Parameter(\n",
    "            nn.init.trunc_normal_(\n",
    "                torch.empty(d_ff, d_model, device=\"cpu\" if device is None else device, dtype=torch.float32 if dtype is None else dtype)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        w1_out = x @ self.W1.T\n",
    "        silu_out = w1_out * F.sigmoid(w1_out)\n",
    "        w3_out = x @ self.W3.T\n",
    "\n",
    "        return (silu_out * w3_out) @ self.W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82fe0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiglu = MySwiGLU(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405beb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694f23f6",
   "metadata": {},
   "source": [
    "### Relative Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351bd7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e97472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec474412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fc2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522321f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64100478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dell-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
